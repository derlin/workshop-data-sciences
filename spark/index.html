
<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
        <meta name="author" content="Lucy Linder (DAPLAB)">
      
      
        <link rel="shortcut icon" href="../assets/images/favicon.png">
      
      <meta name="generator" content="mkdocs-0.16.3, mkdocs-material-1.10.1">
    
    
      
        <title>Spark - Workshop data sciences</title>
      
    
    
      <script src="../assets/javascripts/modernizr-e826f8942a.js"></script>
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application-a20f419c8e.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-23f75ab9c7.palette.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
      <link rel="stylesheet" href="../style.css">
    
    
  </head>
  
  
  
  
    <body data-md-color-primary="blue" data-md-color-accent="orange">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Workshop data sciences" class="md-header-nav__button md-logo">
          
            <i class="md-icon md-icon--home"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
            
            Spark
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result" data-md-lang-search="" data-md-lang-tokenizer="[\s\-]+">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <div class="md-nav__button md-logo">
      
        <i class="md-icon md-icon--home"></i>
      
    </div>
    Workshop data sciences
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../hdfs/" title="HDFS" class="md-nav__link">
      HDFS
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../mapreduce/" title="MapReduce" class="md-nav__link">
      MapReduce
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../hive/" title="Hive" class="md-nav__link">
      Hive
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../zeppelin/" title="Hello Zeppelin" class="md-nav__link">
      Hello Zeppelin
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Spark
      </label>
    
    <a href="./" title="Spark" class="md-nav__link md-nav__link--active">
      Spark
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" title="Introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-we-will-do" title="What we will do" class="md-nav__link">
    What we will do
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-we-will-use" title="What we will use" class="md-nav__link">
    What we will use
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-algorithms" title="Available algorithms" class="md-nav__link">
    Available algorithms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lda-basics" title="LDA Basics" class="md-nav__link">
    LDA Basics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lda-with-pyspark" title="LDA with pyspark" class="md-nav__link">
    LDA with pyspark
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#getting-the-dataset" title="Getting the dataset" class="md-nav__link">
    Getting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-the-dataset-into-spark" title="Loading the dataset into Spark" class="md-nav__link">
    Loading the dataset into Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adding-ids-and-creating-lookup-tables" title="Adding IDs and creating lookup tables" class="md-nav__link">
    Adding IDs and creating lookup tables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#features-extraction" title="Features extraction" class="md-nav__link">
    Features extraction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenisation" title="Tokenisation" class="md-nav__link">
    Tokenisation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stopwords-removal" title="Stopwords removal" class="md-nav__link">
    Stopwords removal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-frequencies-and-vocabulary" title="Word frequencies and vocabulary" class="md-nav__link">
    Word frequencies and vocabulary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" title="TF-IDF" class="md-nav__link">
    TF-IDF
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-the-model" title="Creating the model" class="md-nav__link">
    Creating the model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#describing-the-topics" title="Describing the topics" class="md-nav__link">
    Describing the topics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#queryengine" title="QueryEngine" class="md-nav__link">
    QueryEngine
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-a-queryengine" title="Creating a QueryEngine" class="md-nav__link">
    Creating a QueryEngine
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-the-queryengine" title="Using the QueryEngine" class="md-nav__link">
    Using the QueryEngine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interactive-queries" title="Interactive queries" class="md-nav__link">
    Interactive queries
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#search-in-titles" title="Search in titles" class="md-nav__link">
    Search in titles
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-term" title="Top docs for term" class="md-nav__link">
    Top docs for term
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-terms" title="Top docs for terms" class="md-nav__link">
    Top docs for terms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-doc" title="Top docs for doc" class="md-nav__link">
    Top docs for doc
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../lsa/" title="LSA" class="md-nav__link">
      LSA
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" title="Introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-we-will-do" title="What we will do" class="md-nav__link">
    What we will do
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-we-will-use" title="What we will use" class="md-nav__link">
    What we will use
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-algorithms" title="Available algorithms" class="md-nav__link">
    Available algorithms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lda-basics" title="LDA Basics" class="md-nav__link">
    LDA Basics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lda-with-pyspark" title="LDA with pyspark" class="md-nav__link">
    LDA with pyspark
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#getting-the-dataset" title="Getting the dataset" class="md-nav__link">
    Getting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-the-dataset-into-spark" title="Loading the dataset into Spark" class="md-nav__link">
    Loading the dataset into Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adding-ids-and-creating-lookup-tables" title="Adding IDs and creating lookup tables" class="md-nav__link">
    Adding IDs and creating lookup tables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#features-extraction" title="Features extraction" class="md-nav__link">
    Features extraction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenisation" title="Tokenisation" class="md-nav__link">
    Tokenisation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stopwords-removal" title="Stopwords removal" class="md-nav__link">
    Stopwords removal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-frequencies-and-vocabulary" title="Word frequencies and vocabulary" class="md-nav__link">
    Word frequencies and vocabulary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" title="TF-IDF" class="md-nav__link">
    TF-IDF
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-the-model" title="Creating the model" class="md-nav__link">
    Creating the model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#describing-the-topics" title="Describing the topics" class="md-nav__link">
    Describing the topics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#queryengine" title="QueryEngine" class="md-nav__link">
    QueryEngine
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-a-queryengine" title="Creating a QueryEngine" class="md-nav__link">
    Creating a QueryEngine
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-the-queryengine" title="Using the QueryEngine" class="md-nav__link">
    Using the QueryEngine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interactive-queries" title="Interactive queries" class="md-nav__link">
    Interactive queries
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#search-in-titles" title="Search in titles" class="md-nav__link">
    Search in titles
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-term" title="Top docs for term" class="md-nav__link">
    Top docs for term
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-terms" title="Top docs for terms" class="md-nav__link">
    Top docs for terms
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#top-docs-for-doc" title="Top docs for doc" class="md-nav__link">
    Top docs for doc
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Spark</h1>
                
                <p>In this workshop, we will create a search engine for BBC articles using pyspark and the Spark ML library. </p>
<ul>
<li><a href="" target="_blank">pyspark documentation</a></li>
<li><a href="https://spark.apache.org/docs/2.1.0/ml-guide.html" target="_blank">ML guide</a></li>
</ul>
<h2 id="introduction">Introduction</h2>
<h3 id="what-we-will-do">What we will do</h3>
<p>To create the search engine, we will do the following steps:</p>
<p><img alt="steps" src="../resources/spark-lda-steps.png" /></p>
<h3 id="what-we-will-use">What we will use</h3>
<p>LSA, <em>latent semantic anlysis</em> is</p>
<blockquote>
<p><em>a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms</em> (source: wikipedia)</p>
</blockquote>
<p>In summary, we want to establish underlying relationships between documents in a collection by linking documents and terms through <em>concepts</em>. Those concepts are deduced or constructed through a statistical or mathematical algorithm that forms a <em>model</em>. Once we have the model, we can begin using it for search queries.</p>
<h4 id="available-algorithms">Available algorithms</h4>
<p>There are two well-known methods for discovering underlying topics:</p>
<ol>
<li>
<p><strong>SVD</strong>, <em>Singular Value Decomposition</em>: is a mathematical method for decomposing a matrix into a product of smaller matrices. It has the advantage of being <em>mathematically correct</em>: computing the model, hence  the decomposed matrices, takes only one pass and is deterministic: the same data will always give the same result (as long as the same parameters are used).</p>
</li>
<li>
<p><strong>LDA</strong>, <em>Latent Dirichlet Allocation</em>, is a generative probabilistic model. Based on statistics, many iterations are necessary to get a good-enough model and every run could give a different result. The result is also highly dependant on the parameters we use for the training. </p>
</li>
</ol>
<p>In this workshop, we will use the LDA technique.</p>
<h4 id="lda-basics">LDA Basics</h4>
<p>LDA is like a clustering algorithm where :</p>
<ul>
<li>the <em>cluster centers</em> are the topics;</li>
<li>the <em>training examples</em> are documents;</li>
<li>the <em>features</em> are the word frequencies;</li>
<li>the distance is <del>euclidean</del> based on a statistical model (Bayesian inference rules / Dirichlet distribution)</li>
</ul>
<p>As in clustering, we need to give some informations (<em>parameters</em>) to the model. The most important one is <strong>the number of topics (k)</strong> we think there is (exactly as we need to specify the number of clusters to find).</p>
<p>During training, the model will first assign each document to a random topic. Then, on each iteration, it computes how well the actual topic distribution describes/predicts each document, makes adjustments and try again. Most of the time, the programmer will set in advance the <strong>maximum number of iterations</strong> to do.</p>
<p>In the end, the model outputs a topic distribution over document (how much a document is important to a given topic) and over terms (how much the term describes the topic). Documents with similar topic distributions are likely to be similar, even if they don't use the same words.</p>
<h2 id="lda-with-pyspark">LDA with pyspark</h2>
<h3 id="getting-the-dataset">Getting the dataset</h3>
<p>The dataset "<em>Dataset: BBC</em>" available at: <a href="http://mlg.ucd.ie/datasets/bbc.html" target="_blank">http://mlg.ucd.ie/datasets/bbc.html</a> (we used the raw text files).  It consists of 2225 documents from the BBC news website corresponding to stories in five topical areas (business, entertainment, politics, sport and tech) from 2004-2005.</p>
<p>Since the dataset comes in multiple folders and with some duplicates, we already processed it and made it available in csv or json format. If you are interested, you can get <a href="../resources/bbc-transformer.py" target="_blank">the python script</a> we used for the parsing.</p>
<p>For the workshop, download <a href="../resources/bbc.json" target="_blank">bbc.json</a> and save it in the <code class="codehilite">snorkel/zeppelin/data</code> folder.</p>
<h3 id="loading-the-dataset-into-spark">Loading the dataset into Spark</h3>
<p>Create a new notebook. On the first cell, ensure that the <code class="codehilite">bbc.json</code> file is were it should be by running:</p>
<div class="codehilite"><pre><span></span>%sh
ls data/bbc.json
</pre></div>

<p>The file should be listed in the output.</p>
<p>Now, let's load those data into a Spark dataframe (<a href="https://spark.apache.org/docs/2.1.0/sql-programming-guide.html#json-datasets" target="_blank">documentation</a>):</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s1">&#39;data/bbc.json&#39;</span><span class="p">)</span>
</pre></div>

<p>Ensure this worked by inspecting the dataset:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;number of documents: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">dataset</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;structure: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">dataset</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>number of documents: 2096
structure: DataFrame[summary: string, category: string, content: string, filename: string, title: string]
...
</pre></div>

<h3 id="adding-ids-and-creating-lookup-tables">Adding IDs and creating lookup tables</h3>
<p>In order to keep track of our articles, let's give each line of our "table" a unique ID:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">monotonically_increasing_id</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">LongType</span>

<span class="c1"># This will return a new DF with all the columns + id</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="n">monotonically_increasing_id</span><span class="p">())</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

<p>Then, it would be nice to be quickly able to get an ID given a title and vice-versa. So let's create lookup dictionaries:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">docTitles</span> <span class="o">=</span>  <span class="nb">dict</span><span class="p">([(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()])</span> 
<span class="n">docIds</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()])</span>
</pre></div>

<p>In those lines, we select two columns from our dataframe: <em>id</em> and <em>title</em>. Using <code class="codehilite">collect</code>, we ask Spark to actually execute the selection (it is an <em>action</em>) and get the results into a list of <em>Row</em>. A <code class="codehilite">Row</code> behaves like an untyped array. We convert our rows into tuples and finally cast the list of tuples into a dictionary for quick lookup.</p>
<p>To ensure it works, try to lookup the title of the document with ID 0: <code class="codehilite">docTitles[0]</code>.</p>
<h3 id="features-extraction">Features extraction</h3>
<p>In our case, the feature extraction is applied on the articles body (column <code class="codehilite">content</code>) and contains the following steps:</p>
<ul>
<li>breaking content into words (<em>tokenisation</em>)</li>
<li>removing common words (<em>stopwords removal</em>)</li>
<li>computing the frequencies of each word (<em>count vectors</em>) and selecting a subset of words (<em>vocabulary</em>)</li>
<li>computing the TF-IDF over documents and vocabulary</li>
</ul>
<p>As you will see, all those steps are very common and can be performed using Spark ML utilities.</p>
<h4 id="tokenisation">Tokenisation</h4>
<p>The first thing to do is to break our article's content into tokens. </p>
<p>Have a look at the Spark ML documentation and try to figure out how to tokenise our <code class="codehilite">content</code> column: <a href="https://spark.apache.org/docs/2.1.0/ml-features.html#tokenizer" target="_blank">Spark ML documentation: tokenizer</a>.</p>
<p><em>Tips</em>: discard words of less than 4 characters, save the result into a <code class="codehilite">tokens</code> column.</p>
<details class="solution"><summary>Solution</summary><p>We use the <code class="codehilite">RegexTokenizer</code> with the following arguments:</p><ul><li><code class="codehilite">regex</code>: break by white space character(s) </li><li><code class="codehilite">inputCol</code>: name of the input column, here <code class="codehilite">content</code></li><li><code class="codehilite">outputCol</code>: name of the new column with tokens, here <code class="codehilite">tokens</code></li><li><code class="codehilite">minTokenLength</code>: discard tokens with length &lt; 4</li></ul><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="c1"># import the RegexTokenizer class</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">RegexTokenizer</span>
<span class="c1"># create  a new tokenizer instance</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;[</span><span class="se">\\</span><span class="s2">W_]+&quot;</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;content&quot;</span><span class="p">,</span> 
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">minTokenLength</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># tokenise (and select only the interesting columns to gain space)</span>
<span class="n">tokenized_df</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">)</span>
</pre></div>
</details><p>To visualize the results, lets print the first 100 characters of the first article and some of the resulting tokens:
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>

<span class="n">content</span> <span class="o">=</span> <span class="n">tokenized_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;content&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenized_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;content: </span><span class="si">%s</span><span class="s2">...&quot;</span> <span class="o">%</span> <span class="n">content</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">100</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;tokens:  </span><span class="si">%s</span><span class="s2">..&quot;</span> <span class="o">%</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div></p>
<p>Result:
<div class="codehilite"><pre><span></span><span class="n">content</span><span class="o">:</span> <span class="n">Quarterly</span> <span class="n">profits</span> <span class="n">at</span> <span class="n">US</span> <span class="n">media</span> <span class="n">giant</span> <span class="n">TimeWarner</span> <span class="n">jumped</span> <span class="mi">76</span><span class="o">%</span> <span class="n">to</span> <span class="n">$1</span><span class="o">.</span><span class="mi">13</span><span class="n">bn</span> <span class="o">(</span><span class="err">£</span><span class="mi">600</span><span class="n">m</span><span class="o">)</span> <span class="k">for</span> <span class="n">the</span> <span class="n">three</span> <span class="n">months</span> <span class="n">to</span><span class="o">...</span>
<span class="n">tokens</span><span class="o">:</span>  <span class="n">quarterly</span><span class="o">,</span> <span class="n">profits</span><span class="o">,</span> <span class="n">media</span><span class="o">,</span> <span class="n">giant</span><span class="o">,</span> <span class="n">timewarner</span><span class="o">,</span> <span class="n">jumped</span><span class="o">,</span> <span class="mi">13</span><span class="n">bn</span><span class="o">,</span> <span class="mi">600</span><span class="n">m</span><span class="o">,</span> <span class="n">three</span><span class="o">,</span> <span class="n">months</span><span class="o">..</span>
</pre></div></p>
<details class="tip"><summary>The difficulties of tokenisation</summary><p>Tokenisation is very important in language processing, but it is not an easy task. Here, we separated words based on spaces and removed small words. But is it always a good idea ? It depends... For example:</p><ul><li><code class="codehilite">quarterly profit</code> &rarr; <code class="codehilite">quarterly</code>, <code class="codehilite">profit</code> seems good. But what about <code class="codehilite">New York</code> ? Breaking it down into two tokens might change the way our search engine treats a query about <code class="codehilite">New York</code>... Indeed, if it is considered two tokens, a document with a text "there is a <em>new</em> professor at the <em>York</em> university" becomes relevant as well;</li><li>By removing small words, we might loose informations, such as <code class="codehilite">US</code> or <code class="codehilite">USA</code>;</li><li>Here, our tokeniser treats <code class="codehilite">13bn</code> or <code class="codehilite">600m</code> as tokens. But we can wonder if words with non-letter characters should be kept or not.</li></ul><p>In real-life applications, the tokenizer is often way more complex and augmented with context-sensitive rules and heuristics.</p></details><h4 id="stopwords-removal">Stopwords removal</h4>
<p>We want to remove common words that are likely to appear in every document, hence not very informative. Here, we will use the following:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="c1"># stopwords to use: copy-paste it into a cell</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="s2">&quot;bove,abst,accordance,according,accordingly,across,act,actually,added,adj,affected,affecting,affects,after,afterwards,again,against,ah,all,almost,alone,along,already,also,although,always,am,among,amongst,an,and,announce,another,any,anybody,anyhow,anymore,anyone,anything,anyway,anyways,anywhere,apparently,approximately,are,aren,arent,arise,around,as,aside,ask,asking,at,auth,available,away,awfully,b,back,be,became,because,become,becomes,becoming,been,before,beforehand,begin,beginning,beginnings,begins,behind,being,believe,below,beside,besides,between,beyond,biol,both,brief,briefly,but,by,c,ca,came,can,cannot,can&#39;t,cause,causes,certain,certainly,co,com,come,comes,contain,containing,contains,could,couldnt,d,date,did,didn&#39;t,different,do,does,doesn&#39;t,doing,done,don&#39;t,down,downwards,due,during,e,each,ed,edu,effect,eg,eight,eighty,either,else,elsewhere,end,ending,enough,especially,et,et-al,etc,even,ever,every,everybody,everyone,everything,everywhere,ex,except,f,far,few,ff,fifth,first,five,fix,followed,following,follows,for,former,formerly,forth,found,four,from,further,furthermore,g,gave,get,gets,getting,give,given,gives,giving,go,goes,gone,got,gotten,h,had,happens,hardly,has,hasn&#39;t,have,haven&#39;t,having,he,hed,hence,her,here,hereafter,hereby,herein,heres,hereupon,hers,herself,hes,hi,hid,him,himself,his,hither,home,how,howbeit,however,hundred,i,id,ie,if,i&#39;ll,im,immediate,immediately,importance,important,in,inc,indeed,index,information,instead,into,invention,inward,is,isn&#39;t,it,itd,it&#39;ll,its,itself,i&#39;ve,j,just,k,keep,keeps,kept,kg,km,know,known,knows,l,largely,last,lately,later,latter,latterly,least,less,lest,let,lets,like,liked,likely,line,little,&#39;ll,look,looking,looks,ltd,m,made,mainly,make,makes,many,may,maybe,me,mean,means,meantime,meanwhile,merely,mg,might,million,miss,ml,more,moreover,most,mostly,mr,mrs,much,mug,must,my,myself,n,na,name,namely,nay,nd,near,nearly,necessarily,necessary,need,needs,neither,never,nevertheless,new,next,nine,ninety,no,nobody,non,none,nonetheless,noone,nor,normally,nos,not,noted,nothing,now,nowhere,o,obtain,obtained,obviously,of,off,often,oh,ok,okay,old,omitted,on,once,one,ones,only,onto,or,ord,other,others,otherwise,ought,our,ours,ourselves,out,outside,over,overall,owing,own,p,page,pages,part,particular,particularly,past,per,perhaps,placed,please,plus,poorly,possible,possibly,potentially,pp,predominantly,present,previously,primarily,probably,promptly,proud,provides,put,q,que,quickly,quite,qv,r,ran,rather,rd,re,readily,really,recent,recently,ref,refs,regarding,regardless,regards,related,relatively,research,respectively,resulted,resulting,results,right,run,s,said,same,saw,say,saying,says,sec,section,see,seeing,seem,seemed,seeming,seems,seen,self,selves,sent,seven,several,shall,she,shed,she&#39;ll,shes,should,shouldn&#39;t,show,showed,shown,showns,shows,significant,significantly,similar,similarly,since,six,slightly,so,some,somebody,somehow,someone,somethan,something,sometime,sometimes,somewhat,somewhere,soon,sorry,specifically,specified,specify,specifying,still,stop,strongly,sub,substantially,successfully,such,sufficiently,suggest,sup,sure,t,take,taken,taking,tell,tends,th,than,thank,thanks,thanx,that,that&#39;ll,thats,that&#39;ve,the,their,theirs,them,themselves,then,thence,there,thereafter,thereby,thered,therefore,therein,there&#39;ll,thereof,therere,theres,thereto,thereupon,there&#39;ve,these,they,theyd,they&#39;ll,theyre,they&#39;ve,think,this,those,thou,though,thoughh,thousand,throug,through,throughout,thru,thus,til,tip,to,together,too,took,toward,towards,tried,tries,truly,try,trying,ts,twice,two,u,un,under,unfortunately,unless,unlike,unlikely,until,unto,up,upon,ups,us,use,used,useful,usefully,usefulness,uses,using,usually,v,value,various,&#39;ve,very,via,viz,vol,vols,vs,w,want,wants,was,wasnt,way,we,wed,welcome,we&#39;ll,went,were,werent,we&#39;ve,what,whatever,what&#39;ll,whats,when,whence,whenever,where,whereafter,whereas,whereby,wherein,wheres,whereupon,wherever,whether,which,while,whim,whither,who,whod,whoever,whole,who&#39;ll,whom,whomever,whos,whose,why,widely,willing,wish,with,within,without,wont,words,world,would,wouldnt,www,x,y,yes,yet,you,youd,you&#39;ll,your,youre,yours,yourself,yourselves,you&#39;ve,z,zero,article,about,writes,entry,well,will,newsgroup&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
</pre></div>

<p>Look at the <a href="https://spark.apache.org/docs/2.1.0/ml-features.html#stopwordsremover" target="_blank">Spark ML documentation</a> to remove all the stopwords from our <code class="codehilite">tokens</code> column using a <code class="codehilite">StopWordsRemover</code>.</p>
<details class="solution"><summary>Solution</summary><p>The code is very similar to the tokenisation one:</p><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StopWordsRemover</span>

<span class="n">remover</span> <span class="o">=</span> <span class="n">StopWordsRemover</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;filtered&quot;</span><span class="p">,</span> <span class="n">stopWords</span><span class="o">=</span><span class="n">stopwords</span><span class="p">)</span>
<span class="n">filtered_df</span> <span class="o">=</span> <span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tokenized_df</span><span class="p">)</span>
</pre></div>
</details><p>To visualise the results, let's print the first 18 tokens of a document, with and without stopwords:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="n">filtered_tokens</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;  tokens: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">18</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;filtered: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">18</span><span class="p">]))</span>
</pre></div>

<p>Result:</p>
<p><div class="codehilite"><pre><span></span>  tokens: quarterly, profits, media, giant, timewarner, jumped, 13bn, 600m, three, months, december, from, 639m, year, earlier, firm, which, biggest
filtered: quarterly, profits, media, giant, timewarner, jumped, 13bn, 600m, three, months, december, 639m, year, earlier, firm, biggest, investors, google
</pre></div>
Here, <code class="codehilite">from</code> and <code class="codehilite">which</code> have been removed.</p>
<h4 id="word-frequencies-and-vocabulary">Word frequencies and vocabulary</h4>
<p>Using the <a href="https://spark.apache.org/docs/2.1.0/ml-features.html#countvectorizer" target="_blank">Spark ML CountVectorizer</a>, try to find how to create a model with a vocabulary of 3000 words and a minimum document frequency of 5. Then, use the model over our <code class="codehilite">filtered_df</code> dataset to create a new column named <code class="codehilite">token_counts</code>.</p>
<details class="solution"><summary>Solution</summary><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vocabSize</span> <span class="o">=</span> <span class="mi">3000</span> <span class="c1"># the maximum number of term to retain</span>
<span class="n">minDF</span> <span class="o">=</span> <span class="mi">5</span>        <span class="c1"># the minimum number of different documents a </span>
                 <span class="c1"># term must appear in to be included in the vocabulary.</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">inputCol</span> <span class="o">=</span> <span class="s2">&quot;filtered&quot;</span><span class="p">,</span> <span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;token_counts&quot;</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="n">vocabSize</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="n">minDF</span><span class="p">)</span>

<span class="n">count_model</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span>       <span class="c1"># create model</span>
<span class="n">counted_df</span> <span class="o">=</span> <span class="n">count_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span> <span class="c1"># apply model to our df</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">count_model</span><span class="o">.</span><span class="n">vocabulary</span>             <span class="c1"># extract the vocabulary</span>
</pre></div>
</details><p>If you look at our <code class="codehilite">token_counts</code> column, here is what we get:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">first_doc_freqs</span> <span class="o">=</span> <span class="n">counted_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;token_counts&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="n">first_doc_freqs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

<div class="codehilite"><pre><span></span>SparseVector(3000, {0: 4.0, 2: 2.0, 8: 2.0, 9: 2.0, 11: 1.0, 13: 1.0, 14: 2.0, 25: 1.0, 32: 2.0, 40: 3.0, 43: 1.0, 44: 1.0, 47: 1.0, 55: 1.0, 56: 1.0, 57: 2.0, 65: 2.0, 67: 1.0, 68: 1.0, 69: 2.0, 71: 1.0, 85: 1.0, 89: 1.0, 102: 1.0, 109: 1.0, 115: 1.0, 118: 1.0, 119: 1.0, 123: 1.0, 132: 1.0, 137: 2.0, 140: 4.0, 149: 1.0, 150: 1.0, 156: 1.0, 159: 1.0, 160: 1.0, 161: 1.0, 170: 2.0, 179: 3.0, 189: 1.0, 190: 1.0, 202: 1.0, 205: 1.0, 209: 2.0, 227: 1.0, 248: 1.0, 249: 1.0, 261: 1.0, 283: 1.0, 300: 2.0, 327: 1.0, 331: 2.0, 333: 1.0, 340: 3.0, 342: 1.0, 360: 5.0, 364: 2.0, 410: 1.0, 440: 1.0, 464: 1.0, 467: 1.0, 489: 1.0, 498: 1.0, 504: 1.0, 544: 2.0, 549: 1.0, 560: 1.0, 562: 1.0, 589: 2.0, 632: 1.0, 687: 4.0, 742: 2.0, 779: 1.0, 780: 1.0, 797: 1.0, 806: 3.0, 828: 1.0, 890: 1.0, 931: 1.0, 938: 1.0, 951: 1.0, 960: 1.0, 971: 1.0, 1017: 2.0, 1066: 1.0, 1129: 1.0, 1177: 2.0, 1290: 1.0, 1311: 1.0, 1360: 1.0, 1437: 1.0, 1451: 1.0, 1462: 1.0, 1597: 2.0, 1639: 1.0, 1674: 1.0, 1719: 1.0, 1732: 1.0, 1733: 1.0, 1906: 1.0, 1987: 1.0, 2034: 1.0, 2090: 1.0, 2120: 1.0, 2188: 1.0, 2199: 1.0, 2265: 1.0, 2305: 2.0, 2306: 1.0, 2392: 1.0, 2443: 1.0, 2467: 1.0, 2670: 1.0, 2742: 1.0})
</pre></div>

<details class="tip"><summary>About SparseVector</summary><p>A sparse vector is just a way to compress a vector when it is filled mainly with zeroes. The idea is to only keep track of the length of the vector and the cells with a non-zero value. So in this <code class="codehilite">SparseVector</code>, we have 3000 entries. Index 0 has value <code class="codehilite">4</code>, index 1 has value 0, index 2 has value <code class="codehilite">2</code>, etc. Each index corresponds to the token at the same index in the <code class="codehilite">vocabulary</code>. </p><p>You can convert a <code class="codehilite">SparseVector</code> back into a "normal" vector (called a <code class="codehilite">DenseVector</code>) using:
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="n">Vectors</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mySparseVector</span><span class="p">)</span>
</pre></div></p></details><p>The <code class="codehilite">token_counts</code> column contains a vector of length <code class="codehilite">len(vocabulary)</code>. The value at index <code class="codehilite">x</code> corresponds to the frequency of the token at index <code class="codehilite">x</code> in the <code class="codehilite">vocabulary</code>:</p>
<div class="codehilite"><pre><span></span><span class="n">first_doc_freqs</span> <span class="o">=</span> <span class="n">counted_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;token_counts&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;frequencies of the first ten words of the vocabulary in the first document:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%-10s</span><span class="s2">: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">first_doc_freqs</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>

<p>Result:
<div class="codehilite"><pre><span></span>frequencies of the first ten words of the vocabulary in the first document:
year      : 4
people    : 0
time      : 2
government: 0
years     : 0
best      : 0
told      : 0
game      : 0
three     : 2
film      : 2
</pre></div></p>
<h4 id="tf-idf">TF-IDF</h4>
<p>The <em>term frequency–inverse document frequency</em> (TF-IDF) is often used in information retrieval and search engine. The basic idea is:</p>
<ol>
<li>the more often a searched term appears in a document, the more relevant the document is relative to the search (<em>term frequency</em>);</li>
<li>the more often a term appears in a corpus of document, the less informative/discriminative it is (<em>inverse document frequency</em>).</li>
</ol>
<p>So the TF-IDF is a way to give different weights to search terms and results, in order to get more relevant results.</p>
<p>We already computed the term frequencies using the <code class="codehilite">CountVectorizer</code>. The only thing left to do is to compute the IDF: 
$$ 
idf_t = \frac{N}{df_t}
$$
where <em>N</em> is the number of documents in the corpus and df<sub>t</sub> is the number of documents in which <sub>t</sub> appears.</p>
<p>In Spark ML, the <a href="https://people.apache.org/~pwendell/spark-releases/spark-2.1.0-rc1-docs/ml-features.html#tf-idf" target="_blank">IDF</a> class takes care of everything:</p>
<blockquote>
<p>IDF is an Estimator which is fit on a dataset and produces an IDFModel. The IDFModel takes feature vectors (generally created from HashingTF or CountVectorizer) and scales each column. Intuitively, it down-weights columns which appear frequently in a corpus.</p>
</blockquote>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">IDF</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">inputCol</span> <span class="o">=</span> <span class="s2">&quot;token_counts&quot;</span><span class="p">,</span> <span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">idf_model</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">counted_df</span><span class="p">)</span>
<span class="c1"># apply the model and keep only the relevant columns</span>
<span class="n">features_df</span> <span class="o">=</span> <span class="n">idf_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">counted_df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
</pre></div>

<h3 id="creating-the-model">Creating the model</h3>
<p>Now, that we have our features, let's train an LDA model.</p>
<p>There are many parameters to fine-tune an <a href="https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.clustering.LDA" target="_blank">LDA model</a>. Right now, we will just set two of them:</p>
<ul>
<li><code class="codehilite">k</code>: the number of topics (or clusters) to find;</li>
<li><code class="codehilite">maxIter</code>: the maximum number of iterations to do.</li>
</ul>
<p>Based on the <a href="https://spark.apache.org/docs/2.1.1/ml-clustering.html#latent-dirichlet-allocation-lda" target="_blank">LDA example</a>, we create the model with:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">LDA</span>

<span class="c1"># set parameters</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>        <span class="c1"># number of topics</span>
<span class="n">maxIter</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># low boundary: might not be incredible, but it will be quick</span>

<span class="c1"># train a LDA model.</span>
<span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="n">maxIter</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features_df</span><span class="p">)</span>

<span class="c1"># Add the result to the dataframe</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_df</span><span class="p">)</span>
</pre></div>

<p>The LDA model gives us two important things:</p>
<ol>
<li><code class="codehilite">model.topicsMatrix()</code>: the inferred topics, where each topic is represented by a distribution over terms. It is a matrix of size <code class="codehilite">len(vocabulary)</code> x <code class="codehilite">k</code>, where each column is a topic: value at row 1 and column 2 tells the importance of term 1 for topic 2. </li>
<li>the column <code class="codehilite">topicDistribution</code> in the <code class="codehilite">transformed</code> dataframe: it is a vector of size <code class="codehilite">k</code> whose values are the importance of the document for each topic;</li>
</ol>
<p>Having the relations <em>term</em> &harr; <em>topic</em> and <em>topic</em> &harr; <em>document</em>, we can also deduce the relations <em>term</em> &harr; <em>document</em> (transitivity). </p>
<h3 id="describing-the-topics">Describing the topics</h3>
<p>Ok, now let's look at our topics. The model is not able to tell us exactly what they are, but we can list the most relevant terms of the vocabulary for each topic:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="c1"># This returns a DataFrame[topic: int, termIndices: array&lt;int&gt;, termWeights: array&lt;double&gt;]</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># get the top 5 words</span>

<span class="c1"># Let&#39;s replace the termIndices by the actual terms</span>
<span class="n">topics_descr</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="p">[</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># use a zeppelin trick to display a nice table:</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The topics described by their top-weighted terms:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;%table</span><span class="se">\n</span><span class="s2">id</span><span class="se">\t</span><span class="s2">terms&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">topics_descr</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
</pre></div>

<details class="tip"><summary>Printing tables with Zeppelin</summary><p>If you output the <code class="codehilite"><span class="nf">%table</span></code> <em>shebang</em> followed by lines (ending with <code class="codehilite">\n</code>) with tabs (<code class="codehilite">\t</code>), Zeppelin automagically convert it to a table. Example:
<div class="codehilite"><pre><span></span><span class="nf">%pyspark</span>
<span class="n">print</span><span class="p">(</span><span class="s">&quot;&quot;&quot;</span>
<span class="nf">%table</span>
<span class="n">header</span> <span class="mi">1</span>    <span class="n">header</span> <span class="mi">2</span>
<span class="n">cell</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span>    <span class="n">cell</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span>
<span class="n">cell</span> <span class="mi">2</span><span class="p">,</span><span class="mi">1</span>    <span class="n">cell</span> <span class="mi">2</span><span class="p">,</span><span class="mi">1</span>
<span class="s">&quot;&quot;&quot;)</span>
</pre></div></p></details><h3 id="queryengine">QueryEngine</h3>
<p>To simplify, here is <a href="../resources/QueryEngine.py" target="_blank">a python script</a> defining a <code class="codehilite">QueryEngine</code> class. </p>
<h4 id="creating-a-queryengine">Creating a QueryEngine</h4>
<p>Either copy-paste its content to a new cell or save it to <code class="codehilite">zeppelin/data</code> and import it to the notebook using the following snippet:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="k">exec</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/QueryEngine.py&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>

<details class="tip"><summary>QueryEngine methods</summary><p>You can type <code class="codehilite">help(QueryEngine)</code> in a new cell to get the list of available methods. Here is a summary:</p><ul><li><code class="codehilite">showDoc(docId)</code>: returns the title and content of a document as a string;</li><li><code class="codehilite">topDocsForDoc(docId, top=10)</code>: returns the most relevant documents for a given document;</li><li><code class="codehilite">topDocsForTerm(termId, top=10)</code>: returns the most relevant documents for a given term;</li><li><code class="codehilite">topDocsForTermQuery(termIds, top=10)</code>: returns the most relevant document for a given list of terms;</li><li><code class="codehilite">topTermsForTerm(termId, top=10)</code>: returns the most relevant terms for a given term.</li></ul></details><p>Create a new <code class="codehilite">QueryEngine</code> instance:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">q</span> <span class="o">=</span>  <span class="n">QueryEngine</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">transformed</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">idf_model</span><span class="p">)</span>
</pre></div>

<h4 id="using-the-queryengine">Using the QueryEngine</h4>
<p>Type <code class="codehilite">help(q)</code> to list the <code class="codehilite">QueryEngine</code> method and try the different search functions.</p>
<div class="admonition tip">
<p>You might notice that the <code class="codehilite">QueryEngine</code> works with term and document <em>IDs</em>. </p>
<p>To work with term ids, use the <code class="codehilite">vocabulary</code>:</p>
<ul>
<li><code class="codehilite">vocabulary.index(&quot;computer&quot;)</code>: returns the id of the term <em>computer</em>, or <code class="codehilite">-1</code> if the term is not in the vocabulary;</li>
<li><code class="codehilite">vocabulary[10]</code>: returns the <em>term</em> at id <code class="codehilite">10</code>;</li>
</ul>
<p>For documents, use the <em>lookup tables</em> created at the beginning:</p>
<ul>
<li><code class="codehilite">docTitles[0]</code>: returns the title of document <code class="codehilite">0</code>;</li>
<li><code class="codehilite">docIds[&#39;Awesome title&#39;]</code>: returns the ID of the document with title <em>Awesome title</em>;</li>
</ul>
</div>
<div class="admonition tip">
<p>To display the results nicely, you can use the <code class="codehilite">result2tables(result)</code> method, or simply call <code class="codehilite">toTable()</code> on the results. </p>
</div>
<p>Here is an example:
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="c1"># looking for documents related to term &quot;computer&quot;</span>
<span class="n">termId</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;computer&quot;</span><span class="p">)</span>
<span class="n">q</span><span class="o">.</span><span class="n">topDocsForTerm</span><span class="p">(</span><span class="n">termId</span><span class="p">)</span><span class="o">.</span><span class="n">toTable</span><span class="p">()</span> <span class="c1"># or: results2table(q.topDocsForTerm(termId))</span>
</pre></div></p>
<h3 id="interactive-queries">Interactive queries</h3>
<h4 id="search-in-titles">Search in titles</h4>
<p>First, let's have an interactive cell to search in the document titles. </p>
<p>The <code class="codehilite">z.input(name, default_value)</code> let's you create an interactive form. </p>
<p>The <code class="codehilite">filter</code> method on a dataframe accepts an SQL like clause. For example <code class="codehilite">id &gt; 300</code>, <code class="codehilite">content LIKE &#39;%computer%&#39;</code> or <code class="codehilite">lower(title) = &#39;weak dollar hits reuters&#39;</code>.</p>
<p>Using this, we can create an interactive form for searching for strings in the title:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">terms</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="s2">&quot;search in title:&quot;</span><span class="p">,</span> <span class="s2">&quot;computer&quot;</span><span class="p">)</span> <span class="c1"># get input from the user</span>

<span class="c1"># do the query </span>
<span class="n">results</span> <span class="o">=</span> <span class="n">transformed</span>\
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;lower(title) LIKE &#39;%&quot;</span> <span class="o">+</span> <span class="n">terms</span> <span class="o">+</span> <span class="s2">&quot;%&#39;&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># print the results</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;%table&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;id</span><span class="se">\t</span><span class="s2">title&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="se">\t</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

<h4 id="top-docs-for-term">Top docs for term</h4>
<p>Try to write an interactive query where the user enters a term and the system displays the most relevant documents.</p>
<div class="admonition failure">
<p>Be careful: you need to ensure the term is part of the vocabulary (and retrieve its ID) before calling the <code class="codehilite">QueryEngine</code>.</p>
</div>
<details class="solution"><summary>Solution</summary><p>Here is one way to do it:
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># get the input</span>
<span class="n">term</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="s2">&quot;term:&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">term</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="ow">and</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span>
    <span class="c1"># the term is in the vocabulary, we can proceed</span>
    <span class="n">termId</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;results for term: </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">termId</span><span class="p">))</span>
    <span class="n">q</span><span class="o">.</span><span class="n">topDocsForTerm</span><span class="p">(</span><span class="n">termId</span><span class="p">)</span><span class="o">.</span><span class="n">toTable</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># oups: not in the vocabulary. List some random terms instead.</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not in the vocabulary. Try: </span><span class="si">%s</span><span class="s2">...&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="p">))</span>
</pre></div></p></details><h4 id="top-docs-for-terms">Top docs for terms</h4>
<p>Here, we do quite the same as above, but let the user enter multiple terms (the relevant <code class="codehilite">QueryEngine</code> method is <code class="codehilite">topDocsForTermQuery</code>).</p>
<details class="solution"><summary>Solution</summary><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># get the input</span>
<span class="n">terms</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="s2">&quot;terms, space-separated:&quot;</span><span class="p">)</span>

<span class="c1"># prepare random terms</span>
<span class="n">random_terms</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">if</span> <span class="n">term</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
    <span class="c1"># the term is in the vocabulary, we can proceed</span>
    <span class="n">termIds</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocabulary</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">termIds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;looking for documents matching </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">[</span><span class="n">vocabulary</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">termIds</span><span class="p">])</span>
        <span class="n">q</span><span class="o">.</span><span class="n">topDocsForTermQuery</span><span class="p">(</span><span class="n">termIds</span><span class="p">)</span><span class="o">.</span><span class="n">toTable</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;sorry, those terms are not in the vocabulary. Try: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">random_terms</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># no input. Suggest some terms</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Try: </span><span class="si">%s</span><span class="s2">...&quot;</span> <span class="o">%</span> <span class="n">random_terms</span><span class="p">)</span>
</pre></div>
</details><h4 id="top-docs-for-doc">Top docs for doc</h4>
<p>Here is a code for creating a dropdown with document titles:</p>
<div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="c1"># tip: for better performances, move the next line to its own cell and execute it once only</span>
<span class="n">docSelection</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> - </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">transformed</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()]</span>
<span class="c1"># display the dropdown</span>
<span class="n">docId</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;document&quot;</span><span class="p">,</span> <span class="n">docSelection</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

<p>The <code class="codehilite">docId</code> is the ID of the selected document. Add the code necessary to list relevant documents.</p>
<details class="solution"><summary>Solution</summary><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pyspark</span>
<span class="n">docSelection</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> - </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">transformed</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()]</span>
<span class="n">docId</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;document&quot;</span><span class="p">,</span> <span class="n">docSelection</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Top documents for doc #</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">docId</span><span class="p">)</span>
<span class="n">q</span><span class="o">.</span><span class="n">topDocsForDoc</span><span class="p">(</span><span class="n">docId</span><span class="p">)</span><span class="o">.</span><span class="n">toTable</span><span class="p">()</span>
</pre></div>
</details>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../zeppelin/" title="Hello Zeppelin" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Hello Zeppelin
              </span>
            </div>
          </a>
        
        
          <a href="../lsa/" title="LSA" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                LSA
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 DAPLAB & UNIFR
          </div>
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application-f3ab9e5ff8.js"></script>
      
      
      <script>app.initialize({url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
    
      
    
  </body>
</html>